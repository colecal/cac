import fs from "fs";
import path from "path";

const sources = [
  { source: "Google AI", feed: "https://blog.google/technology/ai/rss/" },
  { source: "OpenAI", feed: "https://openai.com/blog/rss.xml" },
  // export.arxiv.org currently returns a channel-only RSS doc (no items) on this endpoint;
  // rss.arxiv.org includes items.
  { source: "arXiv cs.AI", feed: "http://rss.arxiv.org/rss/cs.AI" },
];

function stripHtml(s) {
  const noCdata = s
    .replace(/^<!\[CDATA\[/, "")
    .replace(/\]\]>$/, "");

  return noCdata
    .replace(/<script[\s\S]*?<\/script>/gi, "")
    .replace(/<style[\s\S]*?<\/style>/gi, "")
    .replace(/<[^>]+>/g, "")
    .replace(/\s+/g, " ")
    .trim();
}

function decodeEntities(s) {
  return s
    .replace(/&amp;/g, "&")
    .replace(/&lt;/g, "<")
    .replace(/&gt;/g, ">")
    .replace(/&quot;/g, '"')
    .replace(/&#39;/g, "'");
}

function getTag(text, tag) {
  const re = new RegExp(`<${tag}[^>]*>([\\s\\S]*?)<\\/${tag}>`, "i");
  const m = text.match(re);
  return m ? m[1].trim() : "";
}

function getAttr(text, tag, attr) {
  const re = new RegExp(
    `<${tag}[^>]*\\s${attr}="([^"]+)"[^>]*\\/?>(?:<\\/${tag}>)?`,
    "i"
  );
  const m = text.match(re);
  return m ? m[1] : "";
}

function extractBlocks(xml, tag) {
  const re = new RegExp(`<${tag}[^>]*>([\\s\\S]*?)<\\/${tag}>`, "gi");
  const out = [];
  let m;
  while ((m = re.exec(xml))) out.push(m[1]);
  return out;
}

function parseFeed(xmlText) {
  // returns array of raw item/entry blocks
  const items = extractBlocks(xmlText, "item");
  if (items.length) return items.map((x) => ({ kind: "rss", raw: x }));
  const entries = extractBlocks(xmlText, "entry");
  return entries.map((x) => ({ kind: "atom", raw: x }));
}

function pickTitle(item) {
  const t = decodeEntities(getTag(item.raw, "title"));
  return stripHtml(t);
}

function pickUrl(item) {
  if (item.kind === "rss") {
    const link = decodeEntities(getTag(item.raw, "link"));
    if (link.startsWith("http")) return link;
    const guid = decodeEntities(getTag(item.raw, "guid"));
    if (guid.startsWith("http")) return guid;
    return "";
  }
  // atom
  const href = decodeEntities(getAttr(item.raw, "link", "href"));
  return href.startsWith("http") ? href : "";
}

function pickDate(item) {
  const raw =
    decodeEntities(getTag(item.raw, "pubDate")) ||
    decodeEntities(getTag(item.raw, "updated")) ||
    decodeEntities(getTag(item.raw, "published"));
  const d = raw ? new Date(raw) : null;
  if (!d || Number.isNaN(d.getTime())) return undefined;
  return d.toISOString().slice(0, 10);
}

function toNewsItem(item, source) {
  const title = pickTitle(item);
  const url = pickUrl(item);
  const date = pickDate(item);
  if (!title || !url) return null;
  return { title, url, source, date };
}

function uniqByUrl(items) {
  const seen = new Set();
  const out = [];
  for (const it of items) {
    if (seen.has(it.url)) continue;
    seen.add(it.url);
    out.push(it);
  }
  return out;
}

function sortByDateDesc(items) {
  return items.sort((a, b) => {
    const ad = a.date ? Date.parse(a.date) : 0;
    const bd = b.date ? Date.parse(b.date) : 0;
    return bd - ad;
  });
}

function emitTs(items) {
  const header = `export type NewsItem = {\n  title: string;\n  url: string;\n  source: string;\n  date?: string;\n};\n\n// Auto-generated by scripts/update-ai-news.mjs (do not hand-edit)\nexport const aiNews: NewsItem[] = [\n`;
  const lines = items.map((it) => {
    const title = it.title.replace(/\\/g, "\\\\").replace(/`/g, "\\`");
    return `  { title: \`${title}\`, url: \`${it.url}\`, source: \`${it.source}\`${it.date ? `, date: \`${it.date}\`` : ""} },`;
  });
  return header + lines.join("\n") + "\n];\n";
}

async function fetchFeed(url) {
  const res = await fetch(url, { headers: { "user-agent": "cac-news-bot" } });
  if (!res.ok) throw new Error(`Failed to fetch ${url}: ${res.status}`);
  return await res.text();
}

function pickDiverse(items, { perSource = 4, total = 12 } = {}) {
  const bySource = new Map();
  for (const it of items) {
    const arr = bySource.get(it.source) ?? [];
    arr.push(it);
    bySource.set(it.source, arr);
  }
  // Ensure each bucket is date-sorted
  for (const [k, arr] of bySource.entries()) {
    bySource.set(k, sortByDateDesc(arr));
  }

  const order = sources.map((s) => s.source);
  const out = [];

  // Round-robin up to perSource per feed
  for (let i = 0; i < perSource; i++) {
    for (const s of order) {
      const arr = bySource.get(s) ?? [];
      if (arr[i]) out.push(arr[i]);
      if (out.length >= total) return uniqByUrl(out);
    }
  }

  // Fill remaining by global recency
  const remaining = sortByDateDesc(uniqByUrl(items)).filter(
    (x) => !out.some((y) => y.url === x.url)
  );
  for (const it of remaining) {
    out.push(it);
    if (out.length >= total) break;
  }
  return uniqByUrl(out);
}

async function main() {
  const all = [];
  for (const s of sources) {
    try {
      const xml = await fetchFeed(s.feed);
      const items = parseFeed(xml)
        .slice(0, 30)
        .map((item) => toNewsItem(item, s.source))
        .filter(Boolean);
      all.push(...items);
    } catch (e) {
      console.error(`Error for ${s.source}:`, e.message);
    }
  }

  const deduped = uniqByUrl(all);
  const diverse = pickDiverse(deduped, { perSource: 4, total: 12 });

  const outPath = path.join(process.cwd(), "src", "data", "aiNews.ts");
  fs.writeFileSync(outPath, emitTs(diverse));
  console.log(`Wrote ${diverse.length} items to ${outPath}`);
}

main().catch((e) => {
  console.error(e);
  process.exit(1);
});
